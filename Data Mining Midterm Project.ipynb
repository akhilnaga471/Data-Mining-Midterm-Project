{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Midterm Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import itertools\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please choose the dataSet you want: \n",
      " 1. Grocery Store \n",
      " 2. Amazon Books \n",
      " 3. Best Buy \n",
      " 4. K-Mart \n",
      " 5. Nike \n",
      " 6. Generic\n",
      "1\n",
      "You selected Grocery Store dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"Please choose the dataSet you want: \\n 1. Grocery Store \\n 2. Amazon Books \\n 3. Best Buy \\n 4. K-Mart \\n 5. Nike \\n 6. Generic\")\n",
    "while True:\n",
    "    choice_of_data=input()\n",
    "    if(choice_of_data=='1'):\n",
    "        data=pd.read_csv(r'C:\\Akhil\\NJIT Courses\\Data Mining\\Grocery Store.csv')\n",
    "        print('You selected Grocery Store dataset')\n",
    "        break\n",
    "    elif(choice_of_data=='2'):\n",
    "        data=pd.read_csv(r'C:\\Akhil\\NJIT Courses\\Data Mining\\AmazonBooks.csv')\n",
    "        print('You selected Amazon Books dataset')\n",
    "        break\n",
    "    elif(choice_of_data=='3'):\n",
    "        data=pd.read_csv(r'C:\\Akhil\\NJIT Courses\\Data Mining\\BestBuy.csv')\n",
    "        print('You selected Best Buy dataset')\n",
    "        break\n",
    "    elif(choice_of_data=='4'):\n",
    "        data=pd.read_csv(r'C:\\Akhil\\NJIT Courses\\Data Mining\\K-Mart.csv')\n",
    "        print('You selected K-Mart dataset')\n",
    "        break\n",
    "    elif(choice_of_data=='5'):\n",
    "        data=pd.read_csv(r'C:\\Akhil\\NJIT Courses\\Data Mining\\Nike.csv')\n",
    "        print('You selected Nike dataset')\n",
    "        break\n",
    "    elif(choice_of_data=='6'):\n",
    "        data=pd.read_csv(r'C:\\Akhil\\NJIT Courses\\Data Mining\\Generic.csv')\n",
    "        print('You selected Generic dataset')\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid selection, please enter the number corresponding to the data\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   milk bread biscuit cornflakes bournvita  jam maggi  tea coffee cock sugar\n",
      "0     t     t       t        NaN       NaN  NaN   NaN  NaN    NaN  NaN   NaN\n",
      "1     t     t       t          t       NaN  NaN   NaN  NaN    NaN  NaN   NaN\n",
      "2   NaN     t     NaN        NaN         t  NaN   NaN    t    NaN  NaN   NaN\n",
      "3     t     t     NaN        NaN       NaN    t     t  NaN    NaN  NaN   NaN\n",
      "4   NaN   NaN       t        NaN       NaN  NaN     t    t    NaN  NaN   NaN\n",
      "5   NaN     t     NaN        NaN         t  NaN   NaN    t    NaN  NaN   NaN\n",
      "6   NaN   NaN     NaN          t       NaN  NaN     t    t    NaN  NaN   NaN\n",
      "7   NaN     t       t        NaN       NaN  NaN     t    t    NaN  NaN   NaN\n",
      "8   NaN     t     NaN        NaN       NaN    t     t    t    NaN  NaN   NaN\n",
      "9     t     t     NaN        NaN       NaN  NaN   NaN  NaN    NaN  NaN   NaN\n",
      "10  NaN   NaN       t          t       NaN  NaN   NaN  NaN      t    t   NaN\n",
      "11  NaN   NaN       t          t       NaN  NaN   NaN  NaN      t    t   NaN\n",
      "12  NaN   NaN     NaN        NaN         t  NaN   NaN  NaN      t  NaN     t\n",
      "13  NaN     t     NaN        NaN       NaN  NaN   NaN  NaN      t    t   NaN\n",
      "14  NaN     t       t        NaN       NaN  NaN   NaN  NaN    NaN  NaN     t\n",
      "15  NaN   NaN     NaN          t       NaN  NaN   NaN  NaN      t  NaN     t\n",
      "16  NaN     t     NaN        NaN         t  NaN   NaN  NaN    NaN  NaN     t\n",
      "17  NaN     t     NaN        NaN       NaN  NaN   NaN  NaN      t  NaN     t\n",
      "18  NaN     t     NaN        NaN       NaN  NaN   NaN  NaN      t  NaN     t\n",
      "19    t   NaN     NaN          t       NaN  NaN   NaN    t      t  NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>milk</th>\n",
       "      <th>bread</th>\n",
       "      <th>biscuit</th>\n",
       "      <th>cornflakes</th>\n",
       "      <th>bournvita</th>\n",
       "      <th>jam</th>\n",
       "      <th>maggi</th>\n",
       "      <th>tea</th>\n",
       "      <th>coffee</th>\n",
       "      <th>cock</th>\n",
       "      <th>sugar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  milk bread biscuit cornflakes bournvita  jam maggi  tea coffee cock sugar\n",
       "0    t     t       t        NaN       NaN  NaN   NaN  NaN    NaN  NaN   NaN\n",
       "1    t     t       t          t       NaN  NaN   NaN  NaN    NaN  NaN   NaN\n",
       "2  NaN     t     NaN        NaN         t  NaN   NaN    t    NaN  NaN   NaN\n",
       "3    t     t     NaN        NaN       NaN    t     t  NaN    NaN  NaN   NaN\n",
       "4  NaN   NaN       t        NaN       NaN  NaN     t    t    NaN  NaN   NaN"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing Each Item from the header of the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'milk': 1,\n",
       " 'bread': 2,\n",
       " 'biscuit': 3,\n",
       " 'cornflakes': 4,\n",
       " 'bournvita': 5,\n",
       " 'jam': 6,\n",
       " 'maggi': 7,\n",
       " 'tea': 8,\n",
       " 'coffee': 9,\n",
       " 'cock': 10,\n",
       " 'sugar': 11}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_list = list(df.columns)\n",
    "item_dict = dict()\n",
    "\n",
    "for i, item in enumerate(item_list):\n",
    "    item_dict[item] = i + 1\n",
    "\n",
    "item_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Transactions from the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{1, 2, 3},\n",
       " {1, 2, 3, 4},\n",
       " {2, 5, 8},\n",
       " {1, 2, 6, 7},\n",
       " {3, 7, 8},\n",
       " {2, 5, 8},\n",
       " {4, 7, 8},\n",
       " {2, 3, 7, 8},\n",
       " {2, 6, 7, 8},\n",
       " {1, 2},\n",
       " {3, 4, 9, 10},\n",
       " {3, 4, 9, 10},\n",
       " {5, 9, 11},\n",
       " {2, 9, 10},\n",
       " {2, 3, 11},\n",
       " {4, 9, 11},\n",
       " {2, 5, 11},\n",
       " {2, 9, 11},\n",
       " {2, 9, 11},\n",
       " {1, 4, 8, 9}]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions = list()\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    transaction = set()\n",
    "    \n",
    "    for item in item_dict:\n",
    "        if row[item] == 't':\n",
    "            transaction.add(item_dict[item])\n",
    "    transactions.append(transaction)\n",
    "    \n",
    "transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Support Function that evaluates the support value for a set given all the transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_support(transactions, item_set):\n",
    "    match_count = 0\n",
    "    for transaction in transactions:\n",
    "        if item_set.issubset(transaction):\n",
    "            match_count += 1\n",
    "            \n",
    "    return float(match_count/len(transactions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# self_join performs join based on the last level valid sets. It joins each sets together by performing union and if the length exceeds the current level, it will skip that set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_join(frequent_item_sets_per_level, level):\n",
    "    current_level_candidates = list()\n",
    "    last_level_items = frequent_item_sets_per_level[level - 1]\n",
    "    \n",
    "    if len(last_level_items) == 0:\n",
    "        return current_level_candidates\n",
    "    \n",
    "    for i in range(len(last_level_items)):\n",
    "        for j in range(i+1, len(last_level_items)):\n",
    "            itemset_i = last_level_items[i][0]\n",
    "            itemset_j = last_level_items[j][0]\n",
    "            union_set = itemset_i.union(itemset_j)\n",
    "            \n",
    "            if union_set not in current_level_candidates and len(union_set) == level:\n",
    "                current_level_candidates.append(union_set)\n",
    "                \n",
    "    return current_level_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pruning function prunes the candidate sets evaluated after completing the self-join part. For each itemset, it finds all its subsets by dropping a single elements from it and checks if that subset was present in the previous level or not. If that subset was not present in the previous level, then the current set is not valid and must not be used, and is thus pruned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_drop_subsets(item_set):\n",
    "    single_drop_subsets = list()\n",
    "    for item in item_set:\n",
    "        temp = item_set.copy()\n",
    "        temp.remove(item)\n",
    "        single_drop_subsets.append(temp)\n",
    "        \n",
    "    return single_drop_subsets\n",
    "\n",
    "def is_valid_set(item_set, prev_level_sets):\n",
    "    single_drop_subsets = get_single_drop_subsets(item_set)\n",
    "    \n",
    "    for single_drop_set in single_drop_subsets:\n",
    "        if single_drop_set not in prev_level_sets:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def pruning(frequent_item_sets_per_level, level, candidate_set):\n",
    "    post_pruning_set = list()\n",
    "    if len(candidate_set) == 0:\n",
    "        return post_pruning_set\n",
    "    \n",
    "    prev_level_sets = list()\n",
    "    for item_set, _ in frequent_item_sets_per_level[level - 1]:\n",
    "        prev_level_sets.append(item_set)\n",
    "        \n",
    "    for item_set in candidate_set:\n",
    "        if is_valid_set(item_set, prev_level_sets):\n",
    "            post_pruning_set.append(item_set)\n",
    "            \n",
    "    return post_pruning_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the main function which uses all the above described Utility functions to implement the Apriori Algorithm and generate the list of frequent itemsets for each level for the provided transactions and min_support value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def apriori(min_support):\n",
    "    frequent_item_sets_per_level = defaultdict(list)\n",
    "    print(\"level : 1\", end = \" \")\n",
    "    \n",
    "    for item in range(1, len(item_list) + 1):\n",
    "        support = get_support(transactions, {item})\n",
    "        if support >= min_support:\n",
    "            frequent_item_sets_per_level[1].append(({item}, support))\n",
    "        \n",
    "    for level in range(2, len(item_list) + 1):\n",
    "        print(level, end = \" \")\n",
    "        current_level_candidates = self_join(frequent_item_sets_per_level, level)\n",
    "\n",
    "        post_pruning_candidates = pruning(frequent_item_sets_per_level, level, current_level_candidates)\n",
    "        if len(post_pruning_candidates) == 0:\n",
    "            break\n",
    "\n",
    "        for item_set in post_pruning_candidates:\n",
    "            support = get_support(transactions, item_set)\n",
    "            if support >= min_support:\n",
    "                frequent_item_sets_per_level[level].append((item_set, support))\n",
    "                \n",
    "    return frequent_item_sets_per_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entering the Minimum Support Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Minimum Support :  20\n",
      "level : 1 2 3 "
     ]
    }
   ],
   "source": [
    "print(\"Enter the Minimum Support : \", end=\" \")\n",
    "min_support = input()\n",
    "min_support = float(min_support)/100\n",
    "frequent_item_sets_per_level = apriori(min_support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the length of Frequent Item sets per level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "for level in frequent_item_sets_per_level:\n",
    "    print(len(frequent_item_sets_per_level[level]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({1}, 0.25), ({2}, 0.65), ({3}, 0.35), ({4}, 0.3), ({5}, 0.2), ({7}, 0.25), ({8}, 0.35), ({9}, 0.4), ({11}, 0.3)]\n",
      "[({1, 2}, 0.2), ({2, 3}, 0.2), ({8, 2}, 0.2), ({2, 11}, 0.2), ({9, 4}, 0.2), ({8, 7}, 0.2), ({9, 11}, 0.2)]\n"
     ]
    }
   ],
   "source": [
    "for level in frequent_item_sets_per_level:\n",
    "    print(frequent_item_sets_per_level[level])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The below code produces a dictionary called item_support_dict which from frequent_item_sets_per_level that maps items to their support values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_support_dict = dict()\n",
    "item_list = list()\n",
    "\n",
    "key_list = list(item_dict.keys())\n",
    "val_list = list(item_dict.values())\n",
    "\n",
    "for level in frequent_item_sets_per_level:\n",
    "    for set_support_pair in frequent_item_sets_per_level[level]:\n",
    "        for i in set_support_pair[0]:\n",
    "            item_list.append(key_list[val_list.index(i)])\n",
    "        item_support_dict[frozenset(item_list)] = set_support_pair[1]\n",
    "        item_list = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The find_subset function takes the item and item_length as parameter and it returns all the possible combinations of elements inside the items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subset(item, item_length):\n",
    "    combs = []\n",
    "    for i in range(1, item_length + 1):\n",
    "        combs.append(list(combinations(item, i)))\n",
    "        \n",
    "    subsets = []\n",
    "    for comb in combs:\n",
    "        for elt in comb:\n",
    "            subsets.append(elt)\n",
    "            \n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This function generates the association rules in accordance withe the minimum confidence value and the provided dictionary of itemsets against their support values. It takes the mininmum confidence value and support_dict as a parameter, and returns rules as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def association_rules(min_confidence, support_dict):\n",
    "    rules = list()\n",
    "    for item, support in support_dict.items():\n",
    "        item_length = len(item)\n",
    "       \n",
    "        if item_length > 1:\n",
    "            subsets = find_subset(item, item_length)\n",
    "           \n",
    "            for A in subsets:\n",
    "                B = item.difference(A)\n",
    "               \n",
    "                if B:\n",
    "                    A = frozenset(A)\n",
    "                    \n",
    "                    AB = A | B\n",
    "                    \n",
    "                    confidence = support_dict[AB] / support_dict[A]\n",
    "                    if confidence >= min_confidence:\n",
    "                        rules.append((A, B, confidence))\n",
    "    \n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Minimum Confidence :  30\n"
     ]
    }
   ],
   "source": [
    "print(\"Enter the Minimum Confidence : \", end=\" \")\n",
    "confidence = input()\n",
    "min_confidence = float(confidence)/100\n",
    "association_rules = association_rules(min_confidence, support_dict = item_support_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rules:  14 \n",
      "\n",
      "{'milk'} -> {'bread'} <confidence: 0.8>\n",
      "{'bread'} -> {'milk'} <confidence: 0.3076923076923077>\n",
      "{'bread'} -> {'biscuit'} <confidence: 0.3076923076923077>\n",
      "{'biscuit'} -> {'bread'} <confidence: 0.5714285714285715>\n",
      "{'bread'} -> {'tea'} <confidence: 0.3076923076923077>\n",
      "{'tea'} -> {'bread'} <confidence: 0.5714285714285715>\n",
      "{'bread'} -> {'sugar'} <confidence: 0.3076923076923077>\n",
      "{'sugar'} -> {'bread'} <confidence: 0.6666666666666667>\n",
      "{'cornflakes'} -> {'coffee'} <confidence: 0.6666666666666667>\n",
      "{'coffee'} -> {'cornflakes'} <confidence: 0.5>\n",
      "{'maggi'} -> {'tea'} <confidence: 0.8>\n",
      "{'tea'} -> {'maggi'} <confidence: 0.5714285714285715>\n",
      "{'coffee'} -> {'sugar'} <confidence: 0.5>\n",
      "{'sugar'} -> {'coffee'} <confidence: 0.6666666666666667>\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rules: \", len(association_rules), \"\\n\")\n",
    "\n",
    "for rule in association_rules:\n",
    "    print('{0} -> {1} <confidence: {2}>'.format(set(rule[0]), set(rule[1]), rule[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
